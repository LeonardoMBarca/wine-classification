{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/leona/OneDrive/Documentos/GitHub/wine-classification/wine_prices/analisys/final_file.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['type'])\n",
    "y = df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for Logistic Regression\n",
    "param_logistic = {\n",
    "    'C': np.array([1, 2, 3, 7, 10, 15, 20, 50]),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938427192514953\n",
      "{'C': 1, 'penalty': None, 'solver': 'newton-cholesky'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "440 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 80, in _check_solver\n",
      "    raise ValueError(\"penalty=None is not supported for the liblinear solver\")\n",
      "ValueError: penalty=None is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.98199088        nan        nan        nan 0.93566163\n",
      " 0.96767786 0.94643596 0.97229502 0.98491597 0.93874033 0.93566163\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.93874033 0.93596956\n",
      "        nan 0.98122153        nan        nan        nan 0.93566163\n",
      " 0.97014117 0.94628211 0.97429538 0.98630142 0.9388943  0.93566163\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.9388943  0.93566163\n",
      "        nan 0.98091337        nan        nan        nan 0.9358156\n",
      " 0.96798579 0.94628211 0.9784523  0.98630153 0.9388943  0.93550779\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.93874033 0.9358156\n",
      "        nan 0.98183715        nan        nan        nan 0.93566163\n",
      " 0.9718349  0.94628211 0.97752899 0.98737881 0.93874033 0.9358156\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.93874033 0.9358156\n",
      "        nan 0.97983609        nan        nan        nan 0.93566163\n",
      " 0.96752378 0.94628211 0.97660603 0.98768639 0.93874033 0.93566163\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.9388943  0.93566175\n",
      "        nan 0.97983549        nan        nan        nan 0.93566163\n",
      " 0.96783159 0.94628211 0.97706674 0.98814792 0.9388943  0.93566163\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.93874033 0.9358156\n",
      "        nan 0.97983597        nan        nan        nan 0.9358156\n",
      " 0.97060094 0.94628211 0.97799064 0.98830189 0.93874033 0.93596956\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.9388943  0.9358156\n",
      "        nan 0.98045123        nan        nan        nan 0.93566163\n",
      " 0.96752401 0.94628211 0.97599053 0.98799396 0.9388943  0.93566175\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.97060105        nan 0.97614437 0.99384272 0.93874033 0.9358156 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(max_iter=2000, tol=0.01, )\n",
    "grid_logistic = GridSearchCV(estimator=logistic, param_grid=param_logistic, cv=strat, n_jobs=-1)\n",
    "grid_logistic.fit(x, y)\n",
    "\n",
    "print(grid_logistic.best_score_)\n",
    "print(grid_logistic.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logistic = LogisticRegression(C=1, penalty=None, solver='newton-cholesky')\n",
    "best_logistic.fit(x_train, y_train)\n",
    "prediction_logistic = best_logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for RandomForestClassifier\n",
    "param_ram = {\n",
    "    'n_estimators': np.array([100, 150]),\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_depth': np.array([4, 6, 8]),\n",
    "    'min_samples_split': np.array([2, 8])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944588144726714\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "ram = RandomForestClassifier()\n",
    "grid_ram = GridSearchCV(estimator=ram, param_grid=param_ram, cv=strat, n_jobs=-1)\n",
    "grid_ram.fit(x, y)\n",
    "\n",
    "print(grid_ram.best_score_)\n",
    "print(grid_ram.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ram = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, n_estimators=100)\n",
    "best_ram.fit(x_train, y_train)\n",
    "prediction_ram = best_ram.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for GradientBoostClassifier\n",
    "param_gradient = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': np.array([0.01, 0.1]),\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'n_estimators': np.array([100, 120])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949203529342098\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'log_loss', 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingClassifier()\n",
    "grid_gradient = GridSearchCV(estimator=gradient, param_grid=param_gradient, cv=strat, n_jobs=-1)\n",
    "grid_gradient.fit(x, y)\n",
    "\n",
    "print(grid_gradient.best_score_)\n",
    "print(grid_gradient.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradient = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.1, loss='log_loss', n_estimators=120)\n",
    "best_gradient.fit(x_train, y_train)\n",
    "prediction_gradient = best_gradient.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for DecisionTreeClassifier\n",
    "param_tree = {\n",
    "    'min_samples_split': np.array([2, 8, 12]),\n",
    "    'max_depth': np.array([4, 6, 8, 12]),\n",
    "    'criterion': [\"gini\", \"entropy\", \"log_loss\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892254396873333\n",
      "{'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "grid_tree = GridSearchCV(estimator=tree, param_grid=param_tree, cv=strat, n_jobs=-1)\n",
    "grid_tree.fit(x, y)\n",
    "\n",
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = DecisionTreeClassifier(criterion='log_loss', max_depth=12, min_samples_split=2)\n",
    "best_tree.fit(x_train, y_train)\n",
    "prediction_tree = best_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param for KNeighborsClassifier\n",
    "param_neigh = {\n",
    "    'weights': ['distance'],\n",
    "    'n_neighbors': np.array([2, 3, 4, 5, 6, 7, 8]),\n",
    "    'metric': ['minkowski', 'chebyshev'],\n",
    "    'p': np.array([1, 2, 3, 4])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649063776869781\n",
      "{'metric': 'minkowski', 'n_neighbors': 8, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier()\n",
    "grid_neigh = GridSearchCV(estimator=neigh, param_grid=param_neigh, cv=strat, n_jobs=-1)\n",
    "grid_neigh.fit(x, y)\n",
    "\n",
    "print(grid_neigh.best_score_)\n",
    "print(grid_neigh.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_neigh = KNeighborsClassifier(metric='minkowski', n_neighbors=6, p=1, weights='distance')\n",
    "best_neigh.fit(x_train, y_train)\n",
    "prediction_neigh = best_neigh.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAUSSIANNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train, y_train)\n",
    "prediction_gauss = gauss.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    {'Model': 'Logistic Regression', 'Accuracy': best_logistic.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_logistic), 'Recall': recall_score(y_test, prediction_logistic), 'ROC_AUC': roc_auc_score(y_test, prediction_logistic), 'f1_score': f1_score(y_test, prediction_logistic)},\n",
    "    {'Model': 'Random Forest', 'Accuracy': best_ram.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_ram), 'Recall': recall_score(y_test, prediction_ram), 'ROC_AUC': roc_auc_score(y_test, prediction_ram), 'f1_score': f1_score(y_test, prediction_ram)},\n",
    "    {'Model': 'Gradient Boosting', 'Accuracy': best_gradient.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_gradient), 'Recall': recall_score(y_test, prediction_gradient), 'ROC_AUC': roc_auc_score(y_test, prediction_gradient), 'f1_score': f1_score(y_test, prediction_gradient)},\n",
    "    {'Model': 'Decision Tree', 'Accuracy': best_tree.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_tree), 'Recall': recall_score(y_test, prediction_tree), 'ROC_AUC': roc_auc_score(y_test, prediction_tree), 'f1_score': f1_score(y_test, prediction_tree)},\n",
    "    {'Model': 'KNeighbors', 'Accuracy': best_neigh.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_neigh), 'Recall': recall_score(y_test, prediction_neigh), 'ROC_AUC': roc_auc_score(y_test, prediction_neigh), 'f1_score': f1_score(y_test, prediction_neigh)},\n",
    "    {'Model': 'GaussianNB', 'Accuracy': gauss.score(x_test, y_test), 'Precision': precision_score(y_test, prediction_gauss), 'Recall': recall_score(y_test, prediction_gauss), 'ROC_AUC': roc_auc_score(y_test, prediction_gauss), 'f1_score': f1_score(y_test, prediction_gauss)}\n",
    "]\n",
    "results = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.994573</td>\n",
       "      <td>0.997279</td>\n",
       "      <td>0.990306</td>\n",
       "      <td>0.995924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.995385</td>\n",
       "      <td>0.994584</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.991327</td>\n",
       "      <td>0.996946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.990327</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.983590</td>\n",
       "      <td>0.989782</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.978593</td>\n",
       "      <td>0.989108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.955746</td>\n",
       "      <td>0.984354</td>\n",
       "      <td>0.922385</td>\n",
       "      <td>0.969839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.968718</td>\n",
       "      <td>0.984859</td>\n",
       "      <td>0.973469</td>\n",
       "      <td>0.963818</td>\n",
       "      <td>0.979131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall   ROC_AUC  f1_score\n",
       "0  Logistic Regression  0.993846   0.994573  0.997279  0.990306  0.995924\n",
       "1        Random Forest  0.995385   0.994584  0.999320  0.991327  0.996946\n",
       "2    Gradient Boosting  0.992821   0.995238  0.995238  0.990327  0.995238\n",
       "3        Decision Tree  0.983590   0.989782  0.988435  0.978593  0.989108\n",
       "4           KNeighbors  0.953846   0.955746  0.984354  0.922385  0.969839\n",
       "5           GaussianNB  0.968718   0.984859  0.973469  0.963818  0.979131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
